---
title: "STAT 240: Probability and Random Variables"
author: "Sahifa Siddiqua"
date: "Spring 2025"
output: rmdformats::readthedown
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE,
                      error = TRUE, fig.height = 4)
library(tidyverse)
source("../../scripts/ggprob.R") # This file contains functions custom written for STAT 240 to visualize probability distributions
```

# Overview

## Learning Outcomes

-   These lectures will teach you how to:
    -   Distinguish between random processes, their outcomes, and the values of random variables
    -   Identify what a valid probability distribution is
    -   Calculate basic properties of probability distributions with base R and tidyverse commands

## Preliminaries

1.  Download the file `week06-probability.Rmd` into `STAT240/lecture/week06-probability`.

## A Note on Our Semester

-   Our long-term goal is to cover **statistical inference**, which is a process for making conclusions about a larger population based on a smaller sample of observed data from that population. Many real world problems can be investigated via statistical inference.

-   Statistical inference requires some knowledge of probability, distributions, random variables, and statistical models.

-   Our goal is *not* to give you a rigorous, comprehensive survey of probability theory; the University has other classes for that!

-   Our goal is to **get you the probability knowledge you need to conduct statistical inference**, and will spend a few lectures working towards this goal.

## LaTeX: For Mathematical Notation

-   Many future lectures in this class will make use of the LaTeX language for writing mathematical notation using only keys on the keyboard.

-   Mathematical notation includes many, many symbols which are not part of the standard keyboard; for example, $\ge$ or $\sigma$.

-   Similar to how we can use markdown language to result in *specific* **formatting** `in the knitted file`, LaTeX provides a way to produce these symbols using keys that are in your keyboard, by surrounding an expression in `$dollar signs$`.

-   For example, the symbol $\ge$ ("greater than or equal to") is written in LaTeX as `$\ge$`, and $\sigma$ ("sigma") is written as `$\sigma$`.

-   We can also create a LaTeX chunk, with two dollar signs on each line delimiting the start and end. Any mathematical notation in the chunk will appear as a larger, centered equation. For example...

$$
\frac{1}{n}\sum_{i=1}^n (x_i - \mu)^2
$$

> You are **not responsible** for learning to write LaTeX, we will never ask you to write LaTeX. However, you are responsible for basic understanding of the mathematical notation it outputs.

# Statistics, Probability, and Distributions

Statistics is primarily the science of studying samples to understand populations. Generally, it's impractical to observe every member of a population, but luckily this is usually not necessary and a well-drawn sample is sufficient to answer most questions.

To understand the notion of statistics and probability we start with understanding all the components involved in it.

## Population vs Sample

A **population** is the particular group of interest that the statistical/research question is dealing with. To answer the statistical/research question one has at hand, one needs to understand this group of interest. When studying the population, the values that change from one member to other in the population is termed as **variable**. (As you might recall, these were the columns of a dataset). The numerical values associated with the population characteristics are called **parameter**. These values are generally unknown and what we want to know about.

A **sample** is a subset of the population such that it shares all the relevant characteristics of the population. A sample or better refered to as a *representative sample* of the population doesn't favor any group of the population over another. The numerical values associated with the sample characteristics are called **statistics**. These values are known and are used to deduce information about the parameters.

## Data and Census

**Data** are the counts, measurements or observations gathered about a specific variable in a population. When data is gathered from every member of the population it is called a **census**.

## Random Processes

-   Our study of **probability** begins with the notion of a **random process**.

> A **random process** is some "experiment" which produces an outcome which is mostly unpredictable. That is, we cannot know for sure what outcome it will produce before it happens. However, we may or may not know the likelihood of each possible outcome.

-   The *outcomes* of these random processes do not have to be numeric.

-   For example, "flipping a coin twice" is a random process, with the possible outcomes H-H, H-T, T-H, or T-T. ("H" for "heads", "T" for "tails".)

-   It is important to acknowledge that a random process **was still random even if it already happened and we know the outcome.**

    -   For example, if we conduct the above random process and flip a coin twice, and we get T-H, that does not mean we always had a 100% chance of getting T-H. The original process was still random.

## Random Variables

-   The basic forms of statistical inference we will cover in this class will require numeric data: a count of something, a proportion, or a continuous response.

-   The outcomes of an experiment do not have to be numeric, such as "heads - tails" from two coin flips; but the **random variable** that arises from the experiment must be a numeric value.

> A **random variable** often denoted as $X$ and $Y$, informally, is the **single numeric quantity of interest** that can take on a new value every time you run a random process/experiment. The set of all possible outcome is called the **sample space** and denoted as $\Omega$.

Sets of possible outcomes are called **events**. Each event has some **probability** associated with it. The probability of some event is denoted as $P(event)$.

-   There are three important features of a random variable:

1.  It is **random**; we cannot predict its value beforehand.
2.  It is **numeric**; this will often take the form of 0 or 1 for variables like "did this happen or not", but it can also be any real number.
3.  It is a **single number** that is generated by one iteration of a random process.

------------------------------------------------------------------------

-   Once again, consider flipping a coin twice, with possible outcomes H-H, H-T, T-H, or T-T.

-   A **random variable** based on this random process could be "The total number of heads observed" - we will denote it as $X$.

    -   *Note: We will always refer to random variables with a capital English letter.*

-   If the outcome is H-H, $X$ is 2. If the outcome is H-T or T-H, $X$ is 1. If the outcome is T-T, $X$ is 0.

-   Note that this value is random, numeric, and reduces the outcome of the experiment to a single number.

------------------------------------------------------------------------

-   Let us extend the experiment to be two rolls of a fair six-sided die. There are 36 possible outcomes to this experiment, including 1 & 1, 1 & 2, 1 & 3, ... 1 & 6, 2 & 1... 6 & 6.

-   The outcomes, as they are, are **not** a random variable; 1 & 2 cannot be the outcome of a random variable because it is not a single number.

-   However, the *sum* of the two dice rolls would be a random variable - let's call it $X$. (The maximum, or the minimum, or any other reducing function which takes in multiple numbers and returns one, are also a valid random variable here.)

-   If the outcome is 1 & 2, $X$ is 3. If the outcome was 5 & 5, 4 & 6, or 6 & 4, $X$ would be 10.

-   $X$ reduces the complex outcome of the experiment down to one number.

## Types of random variables

Random variables are categorized into two types mainly: *categorical* and *numerical* random variables. Numerical variables are further classified into: **discrete** and **continuous** random variables.

We have seen the terms "discrete" and "continuous" before to describe variables in dataframes; we saw it with `scale_*_continuous()` and `scale_*_discrete()`. They apply in a very similar way to probability theory.

-   Discrete Random Variables:

These random variables can only take specific values and are countable. In other words,

> **Discrete** outcomes are those which come from a specific set of **distinct** values or categories (for our ease, we will consider categorical values as discrete variables). If numeric, there must be gaps between the possible values, such as the whole numbers. One could theoretically start from the beginning of the set and start listing the possible values.

Example: A coin toss, a die roll, number of people in a household, etc.

-   Continuous Random Variables:

These random variables take values in a range and are not countable. In other words,

> **Continuous** outcomes are those which may take any value in a specific range, sometimes over all real numbers. There are infinitely many possible values in this range, considering that numbers can have arbitrary number of digits after the decimal point.

Example: Height of people, time to walk to a specific location, percentage grades of a class, etc.

-   Often we will treat a variable as continuous even if we do not *technically* know it to infinite precision or if it exists along a fine grid of technically discrete values.

    -   For example, let's assume that in a list of salaries of employees, salaries are expressed to the nearest cent. Technically, there is only a finite number of discrete salaries that are possible. But we would choose to treat this variable as continuous.

    -   In general, we often choose to treat a variable which is *technically* discrete as continuous if it would be nonsensical to care about each individual value. We do not often go the other way, treating a continuous variable as discrete.

## Probability

-   We do not know which outcome of a random process is going to occur, and therefore we do not know which value a random variable is going to take on.

-   However, we mentioned in the definition of a random process that we sometimes can know the *chance* of each outcome occurring. The field of "probability" is the study of these chances, but more often we will mean...

> The **probability of an outcome** is a single number between 0 and 1 (or equivalently a percentage between 0% and 100%) that indicates how likely you are to get that outcome from the given random process.

-   There is an alternative conceptualization of probability which may or may not speak more to you: If we could run the random process infinitely many times, it is the percentage of those times we would get the given outcome.

------------------------------------------------------------------------

### Sidenote: Probability All Around Us

-   In conversation, we frequently reference probability and randomness (sometimes of a process that has already happened) without talking about the formal mechanisms behind it.

-   For example, consider the following statements which describe probability/randomness of a future process:

    -   *"I might miss my bus if I don't hurry up."*
    -   *"I will need to have a good day on the final to get an A."*

-   These statements reflect how we often think about probability - about not knowing a future outcome.

-   However, consider the following statements which describe probability/randomness about a *past* process:

    -   *"On another day, we would've won that game."*
    -   *"I didn't even leave late or anything, I just hit every red light on the way here."*

-   These are *also* probabilistic statements which imply a past process was random, even though we know what outcome really occurred.

-   Regarding the second example, we can think of the drive somewhere as a random process, which produces a single number: the amount of time it takes you to make it there.

-   Before you drive, you don't know if there will be construction or a road closure, or you'll get unlucky with red lights, or perhaps you will get lucky with green lights. You know about how long it takes on average, but the actual time it takes might vary on any given day.

-   The statement "I didn't even leave late or anything" implies you thought the probability of ending up late was low. And it was, you were right! But low probability does not mean impossible, just unusual.

-   There are many sources of randomness beyond those we have discussed in this brief introduction.

-   **Probability is everywhere, and underpins how we often think and talk about our lives.**

------------------------------------------------------------------------

### Let's Get Numeric

-   The numeric probabilities associated with coin flips and dice rolls are perhaps the most comfortable to us.

    -   The probability of getting "heads" from the flip of a fair coin is 1/2, or 50%.
    -   The probability of getting a 3 from rolling a fair, six-sided dice is 1/6, or $\approx$ 16.7%.

-   We will refer to these probabilities as $P(X = x)$, where $X$ is the random variable, and $x$ is the single numeric value $X$ could take on.

-   However, probability can become more complicated very quickly:

    -   The probability of rolling two dice and having them sum to 10 is 3/36, or $\approx$ 8%.
    -   The probability of a single sampled point from a normal distribution being within one standard deviation of the mean is $\approx$ 68.3%.

Probability has some important laws and axioms that is followed.

## Axioms of Probability

1)  The probability of any event is always non-negative, i.e,

$$P(Event)\ge 0.$$

2)  The probability of the entire sample space is always 1, i.e, $$P(\Omega)=1.$$
3)  The probability of the *union* of *mutually exclusive* events is the sum of the probabilities of each event, i.e,

$$P(A\cup B)= P(A)+P(B).$$

-   We will usually deal with probabilities in the context of a **probability distribution**.

## Corollaries of probability

1)  Probabilities always lie between $0$ and $1$, i.e, $$0 \le P(E) \le 1.$$

2)  Probability of the complimentary events is given by $$P(\text{not E}) = P(E^C) = 1 - P(E).$$

3)  For any event $A$ and $B$, the probability of $A$ or $B$ is given as $$P(A \cup B) = P(A)+P(B)-P(A \cap B).$$

The last corollary is also the generalized for of the $3^{rd}$ axiom.

## Probability Distributions

Lets first understand the concept of probability distribution for discrete random variables.

-   You can define a probability distribution for the outcomes of the random process (e.g. H-H, H-T, T-H, T-T) or for the values of the random variable (e.g. 0, 1, or 2). We will always talk about it in terms of the random variable.

> A **probability distribution** is, informally, the complete enumeration of how likely each possible outcome of a random process or value of a random variable is.

-   For a discrete random variable with a small number of possible outcomes, we can simply list out all probabilities. The distribution in case of discrete random variables is given by a **Probability Mass Function (PMF)**.

-   For a continuous random variable with a large or infinite number of possible outcomes, we can't list out every outcome - so we rely on a function describing how to get the probability from a specific input. The function that gives the ditribution in case of continuous random variables is called by a **Probability Density Function (PDF)**.

-   A valid probability distribution always follows the axioms of probability.

-   For example, the probability distribution for the outcomes of a coin toss is:

Heads: 50% Tails: 50%

-   The probability distribution for the sum of two rolls of a fair sided dice (a random variable) is the following:

```{r}
tibble(x = 2:12, `P(X=x)` = round(c(1:6, 5:1)/36, 2)) %>% print(n = Inf)
```

------------------------------------------------------------------------

## Putting it All Together

-   Now that we have looked at each concept individually, let us synthesize them to see a full back-to-front example of random processes, variables, and probability distributions.

1.  The **random process**, or "experiment", is the original action whose outcome we cannot know ahead of time, like randomly throwing a dart at a dartboard.

2.  The **outcome of that random process** is the spot the dart lands. (Outcomes don't have to be, and often aren't numeric.)

3.  The **random variable**, or "quantity of interest", is the single number of interest which comes from a single iteration of the random process. For example, the score of the dart is a random variable, since every dart throw gives you a single score that could vary from throw to throw.

4.  The **probability distribution** of the random variable considers all possible values the random variable could take on (for a dartboard, you can get most but not all scores 0 through 60 on a single throw) and assigns them a **probability**.

For example, the probability of getting a bullseye (or in terms of the random variable, $P(X = 50)$) is $\approx$ 0.0001%.

# Distribution of Discrete vs. Continuous

-   Both discrete and continuous probability distributions/random variables have to follow the same overarching rules described above, but we handle their math in a slightly different way.

## Probability Mass Function

-   We describe the probability distribution of a discrete random variable with a *Probability Mass Function* (PMF).

> The Probability Mass Function (PMF) is a function that gives the probability at any given point of a discrete random variable. The PMF can be in a table format or given as a function at points x and will be plotted as bar graphs.

Example: The number of Heads (X) when a coin is tossed twice. The sample space created is [HH, TH, HT, TT]. This shows that X can take the values 0 (no heads), 1 (1 head), and 2 (2 heads).

Example: A random variable can have the following pmf

$$f(x) = \left \{
     \begin{array}{ll}
     \frac{1}{4}(1-x) &, x = 0,1 \\
     \frac{1}{4}(x-1) &, x = 2,3 \\
     0, \text{ otherwise.}
     \end{array} \right.$$

-   We name it this because one can imagine that there is "mass"/"weight" resting upon each specific, discrete possible value.

-   For example, the probability distribution of *the number of heads observed* (random variable) from two coin flips (random process) is discrete:

```{r, echo=FALSE}
gbinom(n=2, p=0.5, size=5) +
    theme(axis.text=element_text(size=20),
        axis.title=element_text(size=22,face="bold")) +
  scale_x_continuous(breaks = c(0, 1, 2))
```

-   Notice the two properties being obeyed by this probability distribution:

1.  Every possible outcome (0, 1, and 2) has probability in the range [0%, 100%].

2.  The sum of all probabilities = 0.25 + 0.5 + 0.25 = 100%.

## Probability Distribution Function

-   We describe the probability distribution of a continuous random variable with a *probability density function* (pdf).

> The Probability Density Function (PDF), denoted as $f(x)$, is a function over the sample space $\Omega$, of a continuous random variable $X$ from which the probability that $X$ is within a certain interval can be obtained. The PDF is always given as a function of x where x takes values in a range and is graphed as a curve.

$$P(X\le x) = \int f(x)dx$$

-   The area under the curve in an interval gives the probability of that interval. The total area under the curve is 1, since the total probability is 1.

$$\int_{-\infty}^{\infty} f(x)dx = 1$$

-   This function must never assign negative values or values greater than 1. The probability between two points $a$ and $b$ is given by

$$P(a\le X \le b)=\int_a^b f(x)dx$$

-   Due to calculus, the probability of a continuous random variable at a given point is 0.

$$P(x = a) = P(a \le X \le a) = \int_a^a f(x)dx = 0$$

-   Much like `geom_density`, a probability density function takes on a value at all points which usually (but not always) varies in a smooth curve.

-   Because the pdf has a value at infinitely many points, it does not make sense to "add up every value", and the probability at a single point loses meaning because there are infinitely many.

-   This is why we will rely mostly on area with continuous probability distributions.

-   For example, the probability distribution of *the height in inches of American adult males* is continuous.

```{r echo=FALSE}
gnorm(mu=69,sigma=2.9, size = 3) +
  xlab("Height (in.)") +
  ylab("Density") +
  theme(axis.text=element_text(size=20),
        axis.title=element_text(size=22,face="bold"))
```

-   More theoretically, a random decimal number between 2 and 5 also follows a continuous distribution.

```{r, echo = FALSE}
a = 2
b = 5
ggplot(tibble(x=c(a,b), y=1/(b-a)), aes(x,y)) +
  geom_line(size=3) +
  geom_segment(aes(xend=x, yend=rep(0,2)), size=3) +
  geom_segment(aes(x=a-1, y=0, xend=a, yend=0), size=3) +
  geom_segment(aes(x=b+1, y=0, xend=b, yend=0), size=3) +
  ylim(c(0, 1/(b-a))) +
  xlim(c(a-1, b+1)) +
  scale_x_continuous(breaks = seq(a-1,b+1)) +
  xlab("X") +
  ylab("Density")+
  ggtitle(paste0("Uniform(",a, ", ", b, ")")) +
  theme(axis.text=element_text(size=20),
        axis.title=element_text(size=22,face="bold"))
```

# Properties of Distributions

-   While I think distributions are cool enough on their own, they're also useful beyond just their own set of values.

-   Knowing the probability distribution of a random variable allows us to compute useful measures of center and spread.

-   The next section of this lecture series will walk us through computing these useful measures from a distribution.

## Mean/Expected Value

> The **mean** or **expected value** of a random variable is the average value it would take on with infinitely many iterations of the random process.

-   For discrete variables, the expected value does not have to be a value the random variable can take on. For example, the expected value of a fair roll of a six-sided die is 3.5, even though a single roll cannot return 3.5.

-   The calculation of expected value is conceptually similar, but mathematically different for discrete vs. continuous variables.

### Discrete Case

$$
E(X) = \sum x * P(X = x)
$$

-   Where $x$ represents each of the possible values that the random variable $X$ can take on.

-   The intuition of this formula is that we are taking a modified version of the average of all possible values; but the values $x$ which are more likely to occur are going to have more influence on the final number, through their higher values of $P(X = x)$.

-   For example, to calculate the average value of a single roll of a fair six-sided die (let's call this $D$):

$$
E(D) = 1*P(D = 1) + 2*P(D = 2) + 3*P(D = 3) + 4*P(D = 4) + 5*P(D = 5) + 6*P(D=6)
$$

$$
... = 1*(1/6) + 2*(1/6) + 3*(1/6) + 4*(1/6) + 5*(1/6) + 6*(1/6) = 3.5
$$

### Continuous Case

-   The discrete formula does not apply to continuous variables because there are infinitely many possible values. Therefore, we must rely on integrating over an area rather than summing some point-wise probabilities.

$$
E(X) = \int x \cdot f(x)dx
$$

-   **You will not be asked to evaluate integrals in this class.**

## Standard Deviation & Variance

> The **variance** of a random variable is the expected value of the squared difference from the mean.

### Discrete Case

-   Let $\mu = E(X)$, the expected value of $X$.

$$
Var(X) = \sum (x-\mu)^2*P(X=x)
$$

-   This is similar to the $E(X)$ formula, except the thing we are summing is now $(x-\mu)^2$, the squared distance from the mean, instead of just $x$.

-   For example, to calculate the variance of a single roll of a fair, six-sided dice, once again $D$:

$$
Var(D) = \sum (x-3.5)^2*P(D=x) = (1 - 3.5)^2*P(D = 1) + + ... + (6-3.5)^2*P(D = x)
$$

$$
... = (1 - 3.5)^2*(1/6) + ... + (6-3.5)^2*(1/6) \approx 2.92.
$$

> The **standard deviation** of a random variable is the square root of its variance, and therefore the variance is the square of the standard deviation.

-   Therefore the standard deviation of $D$ above $\approx \sqrt{2.92} \approx = 1.71$; this is on average how far our dice roll will be away from the mean.

### Continuous Case

-   Like the continuous analog of the discrete mean, the continuous analog of the discrete variance replaces the sum with an integral.

$$
Var(X) = \int (x-\mu)^2 \cdot f(x)dx
$$

------------------------------------------------------------------------

-   The variance is often denoted $\sigma^2$, and the standard deviation is then denoted as $\sigma$.

-   By definition, the variance and the standard deviation cannot be negative.

-   These measures show us how varied or spread out the distribution is.



# Some Practice Problems

## Problem 1

A discrete random variable $X$ with possible values $0,1,2,3,4$ has the following partial distribution.

```{r}
## tibble with the distribution
prob1 = tibble(
  x = 0:4,
  p = c(0.15, 0.25, 0.05, 0.35, NA)
)

## long format
prob1

## pretty wide format
prob1 %>%
  pivot_wider(names_from = x, values_from = p) %>% 
  mutate(x = "P(X=x)") %>% 
  relocate(x)
  
```

> What is $P(X = 4)$?

We know for discrete random variables,

$$
\sum_{x} P(X = x) = 1
$$

-   Find the missing $P(X=4)$ so that the sum of probabilities is one.
    -   sum the other probabilities
    -   subtract the total from one
    -   set this to the missing probability

```{r}
# Write your code here!
```

## Problem 2

> What is the mean of the random variable with the previous distribution?

$$
\mu = E(X) = \sum_{x=0}^4 x * P(X=x)
$$

```{r}
# write your code here!
```

-   Note that the mean (expected value) is a **weighted average** of the possible values of the random variable, weighted by their probabilities.

## Problem 3

> What are the variance and standard deviation of the random variable from problem 1?

$$
\sigma^2 = Var(X) = \sum_{x=0}^4 (x - \mu)^2 P(X=x)
$$

## Problem 4

> Draw a graph of the discrete distribution.

-   Use line segments to represent the probabilities

```{r}
# Write your code here
```

## Problem 5

> Add a dashed red line at the mean and dotted black lines one standard deviation above and below the mean.

```{r}
# Write your code here
```

-   Note that the mean is the *balancing point* of the distribution

    -   It does not need to be a possible value of the distribution

-   The majority of the probability is within one standard deviation of the mean

-   But there is some remaining probability outside of this interval

## Problem 6

> Find the probability within one standard deviation of the mean.

```{r}
# Write your code here.
```

## Problem 7

Consider the random experiment of flipping a coin three times.

### a)

List out every possible **outcome** of the three coin flips.

### b)

What are the probabilities of each individual outcome?

## Problem 8

Consider the random variable $X$, which counts the number of heads from three coin flips.

### a)

What are the possible values of $X$? Which outcomes map to those values?

### b)

What is the probability distribution of $X$?

# Solutions

## Problem 1

```{r}
## tibble with the distribution
prob1 = tibble(
  x = 0:4,
  p = c(0.15, 0.25, 0.05, 0.35, NA)
)

## long format
prob1

## pretty wide format
prob1 %>%
  pivot_wider(names_from = x, values_from = p) %>% 
  mutate(x = "P(X=x)") %>% 
  relocate(x)
```

```{r}
partial_sum = prob1 %>% 
  filter(x != 4) %>% 
  summarize(sum_p = sum(p)) %>% 
  pull(sum_p) # new function; dataframe %>% pull(x) is the same as dataframe$x, just more convenient for piping workflow.

p4 = 1 - partial_sum

p4

prob1 = prob1 %>% 
  mutate(p = case_when(
    !is.na(p) ~ p,
    TRUE ~ p4))

## long format
prob1

## pretty wide format
prob1 %>%
  pivot_wider(names_from = x, values_from = p) %>% 
  mutate(x = "P(X=x)") %>% 
  relocate(x)

```

## Problem 2

```{r}
## Calculate the mean using base R code
x = prob1$x
p = prob1$p
mu = sum(x*p)
mu
```

## Problem 3

```{r}
## Base R calculation
## Variance
sigma2 = sum((x-mu)^2*p)
sigma2

## Standard deviation
sigma = sqrt(sigma2)
sigma
```

## Problem 4

```{r}
plot1 = ggplot(prob1, aes(x = x, y = p)) +
  geom_segment(aes(xend = x, yend = 0), color = "blue", size=2) +
  geom_hline(yintercept = 0) +
  ylab("P(X=x)") +
  ggtitle("Distribution of X")

plot1
```

## Problem 5

```{r}
plot1 +
  geom_vline(xintercept = mu, color = "red", linetype = "dashed") +
  geom_vline(xintercept = mu + c(-1,1)*sigma,
             color = "black",
             linetype = "dotted")
```

## Problem 6

```{r}
## base R calculation
p6 = sum(p[x >= mu - sigma & x <= mu + sigma])
p6
```

```{r}
## tidyverse calculation
prob6 = prob1 %>% 
  filter(x >= mu - sigma & x <= mu + sigma) %>% 
  summarize(prob = sum(p))

prob6
```

## Problem 7

Consider the random experiment of flipping a coin three times.

### a)

List out every possible **outcome** of the three coin flips.

> HHH, HHT, HTH, HTT, TTT, TTH, THT, THH

### b)

What are the probabilities of each individual outcome?

> Every individual outcome has probability 0.5 \* 0.5 \* 0.5 = 0.125.

> Another way to arrive at that probability: they're all equally likely, and they must sum to one, and there's 8 outcomes, so each must have probability 1/8 = 0.125.

## Problem 8

Consider the random variable $X$, which counts the number of heads from three coin flips.

### a)

What are the possible values of $X$? Which outcomes map to those values?

> TTT gives X a value of 0. HTT, THT, and TTH give X a value of 1. THH and HHT and HTH give X a value of 2. HHH gives X a value of 3.

### b)

What is the probability distribution of the values of $X$?

$P(X = 0) = 1/8$

$P(X = 1) = 3/8$

$P(X = 2) = 3/8$

$P(X = 3) = 1/8$.
